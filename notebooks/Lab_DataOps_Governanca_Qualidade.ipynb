{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Lab DataOps: Governan√ßa e Qualidade de Dados com PySpark e Great Expectations\n",
    "\n",
    "## Objetivos do Laborat√≥rio\n",
    "\n",
    "Neste laborat√≥rio pr√°tico, voc√™ ir√°:\n",
    "- Implementar **testes de qualidade de dados** automatizados com **Great Expectations**\n",
    "- Aplicar as **6 dimens√µes da qualidade** na pr√°tica\n",
    "- Criar um **pipeline DataOps** com valida√ß√µes profissionais\n",
    "- Simular cen√°rios reais de **governan√ßa de dados**\n",
    "- Gerar **relat√≥rios de qualidade** automatizados\n",
    "\n",
    "### Conceitos Aplicados\n",
    "- **DataOps**: Automa√ß√£o e monitoramento cont√≠nuo\n",
    "- **Governan√ßa**: Regras, pol√≠ticas e responsabilidades\n",
    "- **Qualidade**: Acur√°cia, Completude, Consist√™ncia, Pontualidade, Unicidade e Validade\n",
    "- **Great Expectations**: Framework profissional para valida√ß√£o de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o do Ambiente PySpark e Great Expectations\n",
    "\n",
    "Primeiro, vamos configurar o ambiente PySpark e Great Expectations para nosso laborat√≥rio profissional de qualidade de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala√ß√£o do Great Expectations (execute apenas uma vez)\n",
    "# !pip install great-expectations\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Great Expectations imports\n",
    "import great_expectations as gx\n",
    "from great_expectations.core.batch import RuntimeBatchRequest\n",
    "from great_expectations.profile.user_configurable_profiler import UserConfigurableProfiler\n",
    "from great_expectations.checkpoint import SimpleCheckpoint\n",
    "from great_expectations.exceptions import DataContextError\n",
    "\n",
    "# Inicializar Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"DataOps_Governanca_Lab_GX\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"‚úÖ Spark Session iniciada: {spark.version}\")\n",
    "print(f\"üìä Contexto: {spark.sparkContext.appName}\")\n",
    "print(f\"üéØ Great Expectations vers√£o: {gx.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cria√ß√£o de Dados de Exemplo\n",
    "\n",
    "Vamos criar um dataset simulando dados de **clientes de e-commerce** com problemas de qualidade intencionais para demonstrar os conceitos de governan√ßa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados simulados com problemas de qualidade intencionais\n",
    "dados_clientes = [\n",
    "    (1, \"Jo√£o Silva\", \"joao@email.com\", \"11999887766\", \"2023-01-15\", \"Ativo\", 25, \"SP\"),\n",
    "    (2, \"Maria Santos\", \"maria.santos@gmail.com\", \"11888776655\", \"2023-02-20\", \"Ativo\", 32, \"RJ\"),\n",
    "    (3, \"Pedro\", \"pedro@invalid\", \"119999\", \"2023-03-10\", \"Inativo\", 150, \"MG\"),  # Problemas: email inv√°lido, telefone incompleto, idade imposs√≠vel\n",
    "    (4, \"Ana Costa\", \"ana@email.com\", \"11777665544\", \"2023-04-05\", \"Ativo\", 28, \"SP\"),\n",
    "    (1, \"Jo√£o Silva\", \"joao@email.com\", \"11999887766\", \"2023-01-15\", \"Ativo\", 25, \"SP\"),  # Duplicata\n",
    "    (5, \"\", \"carlos@email.com\", \"11666554433\", \"2023-05-12\", \"Pendente\", None, \"RS\"),  # Nome vazio, idade nula\n",
    "    (6, \"Lucia Oliveira\", \"lucia@email.com\", \"11555443322\", \"2022-12-01\", \"Ativo\", 45, \"BA\"),\n",
    "    (7, \"Roberto Lima\", \"roberto@email.com\", \"11444332211\", \"2023-06-18\", \"Cancelado\", 38, \"PR\"),  # Status n√£o padr√£o\n",
    "    (8, \"Fernanda\", None, \"11333221100\", \"2023-07-22\", \"Ativo\", 29, \"SC\"),  # Email nulo\n",
    "    (9, \"Marcos Pereira\", \"marcos@email.com\", \"11222110099\", \"2023-08-30\", \"Ativo\", -5, \"GO\")  # Idade negativa\n",
    "]\n",
    "\n",
    "# Schema definido (Governan√ßa: Padr√µes de Dados)\n",
    "schema_clientes = StructType([\n",
    "    StructField(\"id_cliente\", IntegerType(), False),\n",
    "    StructField(\"nome\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"telefone\", StringType(), True),\n",
    "    StructField(\"data_cadastro\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"idade\", IntegerType(), True),\n",
    "    StructField(\"estado\", StringType(), True)\n",
    "])\n",
    "\n",
    "df_clientes = spark.createDataFrame(dados_clientes, schema_clientes)\n",
    "print(\"üìã Dataset de clientes criado com problemas de qualidade intencionais\")\n",
    "df_clientes.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configura√ß√£o do Great Expectations\n",
    "\n",
    "Vamos configurar o Great Expectations para criar um **Data Context** e definir nossas **Expectativas de Qualidade**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar diret√≥rio do Great Expectations\n",
    "project_dir = \"/tmp/gx_lab_dataops\"\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "os.chdir(project_dir)\n",
    "\n",
    "# Inicializar Data Context do Great Expectations\n",
    "try:\n",
    "    context = gx.get_context()\n",
    "    print(\"üìÅ Contexto Great Expectations existente carregado\")\n",
    "except DataContextError:\n",
    "    context = gx.get_context(project_root_dir=project_dir)\n",
    "    print(\"üìÅ Novo contexto Great Expectations criado\")\n",
    "\n",
    "# Converter DataFrame Spark para Pandas para Great Expectations\n",
    "df_clientes_pandas = df_clientes.toPandas()\n",
    "\n",
    "print(f\"‚úÖ Great Expectations configurado\")\n",
    "print(f\"üìä Dataset convertido: {len(df_clientes_pandas)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cria√ß√£o de Expectativas de Qualidade com Great Expectations\n",
    "\n",
    "Vamos criar **Expectativas** (Expectations) que representam as **6 dimens√µes da qualidade de dados**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar Datasource para Great Expectations\n",
    "datasource_config = {\n",
    "    \"name\": \"clientes_datasource\",\n",
    "    \"class_name\": \"Datasource\",\n",
    "    \"execution_engine\": {\n",
    "        \"class_name\": \"PandasExecutionEngine\"\n",
    "    },\n",
    "    \"data_connectors\": {\n",
    "        \"runtime_data_connector\": {\n",
    "            \"class_name\": \"RuntimeDataConnector\",\n",
    "            \"batch_identifiers\": [\"default_identifier_name\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Adicionar datasource ao contexto\n",
    "try:\n",
    "    context.add_datasource(**datasource_config)\n",
    "    print(\"‚úÖ Datasource 'clientes_datasource' criado\")\n",
    "except Exception as e:\n",
    "    print(f\"üìã Datasource j√° existe ou erro: {str(e)[:100]}...\")\n",
    "\n",
    "# Criar Expectation Suite (conjunto de expectativas)\n",
    "suite_name = \"clientes_quality_suite\"\n",
    "try:\n",
    "    suite = context.create_expectation_suite(suite_name, overwrite_existing=True)\n",
    "    print(f\"‚úÖ Expectation Suite '{suite_name}' criado\")\n",
    "except Exception as e:\n",
    "    suite = context.get_expectation_suite(suite_name)\n",
    "    print(f\"üìã Expectation Suite '{suite_name}' j√° existe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Definindo Expectativas das 6 Dimens√µes da Qualidade\n",
    "\n",
    "Vamos criar expectativas espec√≠ficas para cada dimens√£o da qualidade usando Great Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar batch request para os dados\n",
    "batch_request = RuntimeBatchRequest(\n",
    "    datasource_name=\"clientes_datasource\",\n",
    "    data_connector_name=\"runtime_data_connector\",\n",
    "    data_asset_name=\"clientes_dataset\",\n",
    "    runtime_parameters={\"batch_data\": df_clientes_pandas},\n",
    "    batch_identifiers={\"default_identifier_name\": \"clientes_batch\"}\n",
    ")\n",
    "\n",
    "# Obter validator para criar expectativas\n",
    "validator = context.get_validator(\n",
    "    batch_request=batch_request,\n",
    "    expectation_suite_name=suite_name\n",
    ")\n",
    "\n",
    "print(\"üéØ CRIANDO EXPECTATIVAS DAS 6 DIMENS√ïES DA QUALIDADE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. COMPLETUDE (Completeness) - Campos n√£o podem ser nulos\n",
    "print(\"\\nüìä 1. COMPLETUDE - Campos obrigat√≥rios\")\n",
    "validator.expect_column_values_to_not_be_null(\"id_cliente\")\n",
    "validator.expect_column_values_to_not_be_null(\"nome\")\n",
    "validator.expect_column_values_to_not_be_null(\"email\")\n",
    "print(\"   ‚úÖ Expectativas de completude criadas\")\n",
    "\n",
    "# 2. UNICIDADE (Uniqueness) - Valores √∫nicos\n",
    "print(\"\\nüîë 2. UNICIDADE - Chaves √∫nicas\")\n",
    "validator.expect_column_values_to_be_unique(\"id_cliente\")\n",
    "validator.expect_column_values_to_be_unique(\"email\")\n",
    "print(\"   ‚úÖ Expectativas de unicidade criadas\")\n",
    "\n",
    "# 3. VALIDADE (Validity) - Formatos e dom√≠nios\n",
    "print(\"\\n‚úÖ 3. VALIDADE - Formatos e dom√≠nios\")\n",
    "# Email v√°lido\n",
    "validator.expect_column_values_to_match_regex(\n",
    "    \"email\", \n",
    "    r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\n",
    ")\n",
    "# Idade v√°lida (0-120)\n",
    "validator.expect_column_values_to_be_between(\"idade\", min_value=0, max_value=120)\n",
    "# Status v√°lido\n",
    "validator.expect_column_values_to_be_in_set(\"status\", [\"Ativo\", \"Inativo\", \"Pendente\"])\n",
    "print(\"   ‚úÖ Expectativas de validade criadas\")\n",
    "\n",
    "# 4. CONSIST√äNCIA (Consistency) - Regras de neg√≥cio\n",
    "print(\"\\nüîÑ 4. CONSIST√äNCIA - Regras de neg√≥cio\")\n",
    "# Telefone deve ter 11 d√≠gitos\n",
    "validator.expect_column_value_lengths_to_equal(\"telefone\", 11)\n",
    "# Data de cadastro n√£o pode ser futura\n",
    "validator.expect_column_values_to_be_dateutil_parseable(\"data_cadastro\")\n",
    "print(\"   ‚úÖ Expectativas de consist√™ncia criadas\")\n",
    "\n",
    "# 5. PONTUALIDADE (Timeliness) - Dados atuais\n",
    "print(\"\\n‚è∞ 5. PONTUALIDADE - Dados atuais\")\n",
    "# Data de cadastro deve ser dos √∫ltimos 2 anos\n",
    "data_limite = (datetime.now() - timedelta(days=730)).strftime(\"%Y-%m-%d\")\n",
    "validator.expect_column_values_to_be_between(\n",
    "    \"data_cadastro\", \n",
    "    min_value=data_limite, \n",
    "    max_value=datetime.now().strftime(\"%Y-%m-%d\")\n",
    ")\n",
    "print(\"   ‚úÖ Expectativas de pontualidade criadas\")\n",
    "\n",
    "# 6. ACUR√ÅCIA (Accuracy) - Dados corretos\n",
    "print(\"\\nüéØ 6. ACUR√ÅCIA - Dados corretos\")\n",
    "# Nome n√£o pode ser vazio\n",
    "validator.expect_column_values_to_not_match_regex(\"nome\", r\"^\\s*$\")\n",
    "# Estado deve ser sigla v√°lida (2 caracteres)\n",
    "validator.expect_column_value_lengths_to_equal(\"estado\", 2)\n",
    "print(\"   ‚úÖ Expectativas de acur√°cia criadas\")\n",
    "\n",
    "# Salvar expectation suite\n",
    "validator.save_expectation_suite(discard_failed_expectations=False)\n",
    "print(\"\\nüíæ Expectation Suite salvo com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Execu√ß√£o das Valida√ß√µes com Great Expectations\n",
    "\n",
    "Agora vamos executar todas as valida√ß√µes e gerar um **relat√≥rio de qualidade** profissional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar valida√ß√µes\n",
    "print(\"üîç EXECUTANDO VALIDA√á√ïES DE QUALIDADE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Validar os dados\n",
    "validation_result = validator.validate()\n",
    "\n",
    "# Analisar resultados\n",
    "print(f\"\\nüìä RESULTADOS DA VALIDA√á√ÉO:\")\n",
    "print(f\"   Total de expectativas: {validation_result.statistics['evaluated_expectations']}\")\n",
    "print(f\"   Expectativas que passaram: {validation_result.statistics['successful_expectations']}\")\n",
    "print(f\"   Expectativas que falharam: {validation_result.statistics['unsuccessful_expectations']}\")\n",
    "print(f\"   Taxa de sucesso: {validation_result.statistics['success_percent']:.1f}%\")\n",
    "\n",
    "# Status geral\n",
    "if validation_result.success:\n",
    "    print(\"\\n‚úÖ VALIDA√á√ÉO PASSOU - Dados dentro dos padr√µes de qualidade\")\n",
    "else:\n",
    "    print(\"\\n‚ùå VALIDA√á√ÉO FALHOU - Problemas de qualidade detectados\")\n",
    "    print(\"\\nüö® PROBLEMAS ENCONTRADOS:\")\n",
    "    \n",
    "    for result in validation_result.results:\n",
    "        if not result.success:\n",
    "            expectation_type = result.expectation_config.expectation_type\n",
    "            column = result.expectation_config.kwargs.get('column', 'N/A')\n",
    "            print(f\"   ‚ùå {expectation_type} - Coluna: {column}\")\n",
    "            if 'partial_unexpected_count' in result.result:\n",
    "                print(f\"      Registros com problema: {result.result['partial_unexpected_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cria√ß√£o de Checkpoint para Automa√ß√£o\n",
    "\n",
    "Vamos criar um **Checkpoint** para automatizar as valida√ß√µes no pipeline DataOps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar checkpoint para automa√ß√£o\n",
    "checkpoint_name = \"clientes_quality_checkpoint\"\n",
    "\n",
    "checkpoint_config = {\n",
    "    \"name\": checkpoint_name,\n",
    "    \"config_version\": 1.0,\n",
    "    \"template_name\": None,\n",
    "    \"module_name\": \"great_expectations.checkpoint\",\n",
    "    \"class_name\": \"Checkpoint\",\n",
    "    \"run_name_template\": \"%Y%m%d-%H%M%S-clientes-validation\",\n",
    "    \"expectation_suite_name\": suite_name,\n",
    "    \"batch_request\": {\n",
    "        \"datasource_name\": \"clientes_datasource\",\n",
    "        \"data_connector_name\": \"runtime_data_connector\",\n",
    "        \"data_asset_name\": \"clientes_dataset\"\n",
    "    },\n",
    "    \"action_list\": [\n",
    "        {\n",
    "            \"name\": \"store_validation_result\",\n",
    "            \"action\": {\"class_name\": \"StoreValidationResultAction\"},\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"update_data_docs\",\n",
    "            \"action\": {\"class_name\": \"UpdateDataDocsAction\"},\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Adicionar checkpoint\n",
    "try:\n",
    "    context.add_checkpoint(**checkpoint_config)\n",
    "    print(f\"‚úÖ Checkpoint '{checkpoint_name}' criado com sucesso\")\n",
    "except Exception as e:\n",
    "    print(f\"üìã Checkpoint j√° existe: {str(e)[:100]}...\")\n",
    "\n",
    "print(\"\\nüîÑ EXECUTANDO CHECKPOINT AUTOMATIZADO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Executar checkpoint\n",
    "checkpoint_result = context.run_checkpoint(\n",
    "    checkpoint_name=checkpoint_name,\n",
    "    batch_request={\n",
    "        \"runtime_parameters\": {\"batch_data\": df_clientes_pandas},\n",
    "        \"batch_identifiers\": {\"default_identifier_name\": \"clientes_batch\"}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Checkpoint executado - Sucesso: {checkpoint_result.success}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Corre√ß√£o de Dados e Re-valida√ß√£o\n",
    "\n",
    "Vamos corrigir os problemas identificados e executar novamente as valida√ß√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrigir_dados_qualidade_gx(df_spark):\n",
    "    \"\"\"\n",
    "    Aplica corre√ß√µes baseadas nos resultados do Great Expectations\n",
    "    \"\"\"\n",
    "    print(\"üîß APLICANDO CORRE√á√ïES DE QUALIDADE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 1. Remover duplicatas (manter primeira ocorr√™ncia)\n",
    "    df_corrigido = df_spark.dropDuplicates([\"id_cliente\"])\n",
    "    print(f\"‚úÖ Duplicatas removidas: {df_spark.count() - df_corrigido.count()} registros\")\n",
    "    \n",
    "    # 2. Corrigir idades inv√°lidas\n",
    "    df_corrigido = df_corrigido.withColumn(\n",
    "        \"idade\",\n",
    "        when((col(\"idade\") < 0) | (col(\"idade\") > 120), None)\n",
    "        .otherwise(col(\"idade\"))\n",
    "    )\n",
    "    print(\"‚úÖ Idades inv√°lidas corrigidas\")\n",
    "    \n",
    "    # 3. Padronizar status\n",
    "    df_corrigido = df_corrigido.withColumn(\n",
    "        \"status\",\n",
    "        when(col(\"status\") == \"Cancelado\", \"Inativo\")\n",
    "        .otherwise(col(\"status\"))\n",
    "    )\n",
    "    print(\"‚úÖ Status padronizados\")\n",
    "    \n",
    "    # 4. Remover registros com campos cr√≠ticos vazios\n",
    "    df_corrigido = df_corrigido.filter(\n",
    "        col(\"nome\").isNotNull() & \n",
    "        (col(\"nome\") != \"\") &\n",
    "        col(\"email\").isNotNull()\n",
    "    )\n",
    "    print(\"‚úÖ Registros com campos cr√≠ticos vazios removidos\")\n",
    "    \n",
    "    print(f\"\\nüìä Registros ap√≥s corre√ß√£o: {df_corrigido.count()}\")\n",
    "    return df_corrigido\n",
    "\n",
    "# Aplicar corre√ß√µes\n",
    "df_clientes_corrigido = corrigir_dados_qualidade_gx(df_clientes)\n",
    "df_clientes_corrigido_pandas = df_clientes_corrigido.toPandas()\n",
    "\n",
    "print(\"\\nüìã Dados ap√≥s corre√ß√£o:\")\n",
    "df_clientes_corrigido.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Re-valida√ß√£o com Dados Corrigidos\n",
    "\n",
    "Vamos executar as valida√ß√µes novamente com os dados corrigidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ RE-VALIDA√á√ÉO COM DADOS CORRIGIDOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Executar checkpoint com dados corrigidos\n",
    "checkpoint_result_corrigido = context.run_checkpoint(\n",
    "    checkpoint_name=checkpoint_name,\n",
    "    batch_request={\n",
    "        \"runtime_parameters\": {\"batch_data\": df_clientes_corrigido_pandas},\n",
    "        \"batch_identifiers\": {\"default_identifier_name\": \"clientes_batch_corrigido\"}\n",
    "    }\n",
    ")\n",
    "\n",
    "# Comparar resultados\n",
    "validation_result_corrigido = checkpoint_result_corrigido.list_validation_results()[0]\n",
    "\n",
    "print(\"\\nüìä COMPARA√á√ÉO DE RESULTADOS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"DADOS ORIGINAIS:\")\n",
    "print(f\"   Taxa de sucesso: {validation_result.statistics['success_percent']:.1f}%\")\n",
    "print(f\"   Expectativas que falharam: {validation_result.statistics['unsuccessful_expectations']}\")\n",
    "\n",
    "print(f\"\\nDADOS CORRIGIDOS:\")\n",
    "print(f\"   Taxa de sucesso: {validation_result_corrigido.statistics['success_percent']:.1f}%\")\n",
    "print(f\"   Expectativas que falharam: {validation_result_corrigido.statistics['unsuccessful_expectations']}\")\n",
    "\n",
    "if validation_result_corrigido.success:\n",
    "    print(\"\\nüéâ SUCESSO! Dados corrigidos passaram em todas as valida√ß√µes\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Ainda existem problemas nos dados corrigidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Gera√ß√£o de Relat√≥rios de Qualidade\n",
    "\n",
    "Vamos gerar **Data Docs** - relat√≥rios HTML profissionais do Great Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar Data Docs (relat√≥rios HTML)\n",
    "print(\"üìà GERANDO RELAT√ìRIOS DE QUALIDADE (DATA DOCS)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Construir Data Docs\n",
    "    context.build_data_docs()\n",
    "    \n",
    "    # Obter URLs dos relat√≥rios\n",
    "    data_docs_sites = context.get_docs_sites_urls()\n",
    "    \n",
    "    print(\"‚úÖ Relat√≥rios de qualidade gerados com sucesso!\")\n",
    "    print(\"\\nüìä RELAT√ìRIOS DISPON√çVEIS:\")\n",
    "    \n",
    "    for site_name, url in data_docs_sites.items():\n",
    "        print(f\"   üìã {site_name}: {url}\")\n",
    "        \n",
    "    print(\"\\nüí° Abra os URLs acima no navegador para visualizar os relat√≥rios detalhados\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erro ao gerar Data Docs: {str(e)}\")\n",
    "\n",
    "# Resumo executivo\n",
    "print(\"\\nüìã RESUMO EXECUTIVO DE QUALIDADE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Dataset Original:\")\n",
    "print(f\"   - Registros: {len(df_clientes_pandas)}\")\n",
    "print(f\"   - Taxa de qualidade: {validation_result.statistics['success_percent']:.1f}%\")\n",
    "print(f\"   - Status: {'‚úÖ APROVADO' if validation_result.success else '‚ùå REPROVADO'}\")\n",
    "\n",
    "print(f\"\\nüìä Dataset Corrigido:\")\n",
    "print(f\"   - Registros: {len(df_clientes_corrigido_pandas)}\")\n",
    "print(f\"   - Taxa de qualidade: {validation_result_corrigido.statistics['success_percent']:.1f}%\")\n",
    "print(f\"   - Status: {'‚úÖ APROVADO' if validation_result_corrigido.success else '‚ùå REPROVADO'}\")\n",
    "\n",
    "melhoria = validation_result_corrigido.statistics['success_percent'] - validation_result.statistics['success_percent']\n",
    "print(f\"\\nüéØ Melhoria alcan√ßada: +{melhoria:.1f} pontos percentuais\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Pipeline DataOps Automatizado com Great Expectations\n",
    "\n",
    "Vamos criar uma fun√ß√£o que integra tudo em um **pipeline DataOps** completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_dataops_great_expectations(df_spark, context, checkpoint_name):\n",
    "    \"\"\"\n",
    "    Pipeline DataOps completo usando Great Expectations\n",
    "    \"\"\"\n",
    "    print(\"üöÄ PIPELINE DATAOPS COM GREAT EXPECTATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    pipeline_result = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"status\": \"EXECUTANDO\",\n",
    "        \"etapas_concluidas\": [],\n",
    "        \"problemas_encontrados\": [],\n",
    "        \"metricas_qualidade\": {}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Etapa 1: Valida√ß√£o inicial\n",
    "        print(\"\\nüìä Etapa 1: Valida√ß√£o inicial dos dados\")\n",
    "        df_pandas = df_spark.toPandas()\n",
    "        \n",
    "        checkpoint_result = context.run_checkpoint(\n",
    "            checkpoint_name=checkpoint_name,\n",
    "            batch_request={\n",
    "                \"runtime_parameters\": {\"batch_data\": df_pandas},\n",
    "                \"batch_identifiers\": {\"default_identifier_name\": \"pipeline_batch\"}\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        validation_result = checkpoint_result.list_validation_results()[0]\n",
    "        pipeline_result[\"etapas_concluidas\"].append(\"validacao_inicial\")\n",
    "        pipeline_result[\"metricas_qualidade\"][\"inicial\"] = validation_result.statistics\n",
    "        \n",
    "        print(f\"   Taxa de qualidade inicial: {validation_result.statistics['success_percent']:.1f}%\")\n",
    "        \n",
    "        # Etapa 2: Corre√ß√£o autom√°tica (se necess√°rio)\n",
    "        if not validation_result.success:\n",
    "            print(\"\\nüîß Etapa 2: Aplicando corre√ß√µes autom√°ticas\")\n",
    "            df_corrigido = corrigir_dados_qualidade_gx(df_spark)\n",
    "            pipeline_result[\"etapas_concluidas\"].append(\"correcao_automatica\")\n",
    "            \n",
    "            # Etapa 3: Re-valida√ß√£o\n",
    "            print(\"\\nüîç Etapa 3: Re-valida√ß√£o dos dados corrigidos\")\n",
    "            df_corrigido_pandas = df_corrigido.toPandas()\n",
    "            \n",
    "            checkpoint_result_final = context.run_checkpoint(\n",
    "                checkpoint_name=checkpoint_name,\n",
    "                batch_request={\n",
    "                    \"runtime_parameters\": {\"batch_data\": df_corrigido_pandas},\n",
    "                    \"batch_identifiers\": {\"default_identifier_name\": \"pipeline_batch_final\"}\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            validation_result_final = checkpoint_result_final.list_validation_results()[0]\n",
    "            pipeline_result[\"etapas_concluidas\"].append(\"revalidacao\")\n",
    "            pipeline_result[\"metricas_qualidade\"][\"final\"] = validation_result_final.statistics\n",
    "            \n",
    "            print(f\"   Taxa de qualidade final: {validation_result_final.statistics['success_percent']:.1f}%\")\n",
    "            \n",
    "            # Determinar status final\n",
    "            if validation_result_final.success:\n",
    "                pipeline_result[\"status\"] = \"‚úÖ SUCESSO\"\n",
    "                print(\"\\nüéâ PIPELINE CONCLU√çDO COM SUCESSO!\")\n",
    "            else:\n",
    "                pipeline_result[\"status\"] = \"‚ö†Ô∏è SUCESSO PARCIAL\"\n",
    "                print(\"\\n‚ö†Ô∏è Pipeline conclu√≠do com melhorias, mas ainda h√° problemas\")\n",
    "        else:\n",
    "            pipeline_result[\"status\"] = \"‚úÖ SUCESSO\"\n",
    "            print(\"\\nüéâ DADOS J√Å EST√ÉO EM CONFORMIDADE!\")\n",
    "        \n",
    "        # Etapa 4: Gera√ß√£o de relat√≥rios\n",
    "        print(\"\\nüìà Etapa 4: Gerando relat√≥rios de qualidade\")\n",
    "        context.build_data_docs()\n",
    "        pipeline_result[\"etapas_concluidas\"].append(\"relatorios_gerados\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        pipeline_result[\"status\"] = \"‚ùå ERRO\"\n",
    "        pipeline_result[\"erro\"] = str(e)\n",
    "        print(f\"\\nüí• ERRO NO PIPELINE: {e}\")\n",
    "    \n",
    "    return pipeline_result\n",
    "\n",
    "# Executar pipeline completo\n",
    "resultado_pipeline = pipeline_dataops_great_expectations(\n",
    "    df_clientes, \n",
    "    context, \n",
    "    checkpoint_name\n",
    ")\n",
    "\n",
    "print(f\"\\nüìã Status final do pipeline: {resultado_pipeline['status']}\")\n",
    "print(f\"üìÖ Timestamp: {resultado_pipeline['timestamp']}\")\n",
    "print(f\"‚úÖ Etapas conclu√≠das: {', '.join(resultado_pipeline['etapas_concluidas'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclus√µes e Pr√≥ximos Passos\n",
    "\n",
    "### üéØ O que Aprendemos com Great Expectations\n",
    "\n",
    "Neste laborat√≥rio, implementamos um **pipeline DataOps profissional** usando Great Expectations:\n",
    "\n",
    "#### ‚úÖ Vantagens do Great Expectations:\n",
    "- **Padroniza√ß√£o**: Expectativas consistentes e reutiliz√°veis\n",
    "- **Automa√ß√£o**: Checkpoints para execu√ß√£o automatizada\n",
    "- **Relat√≥rios**: Data Docs profissionais em HTML\n",
    "- **Integra√ß√£o**: F√°cil integra√ß√£o com pipelines de dados\n",
    "- **Versionamento**: Controle de vers√£o das expectativas\n",
    "\n",
    "#### ‚úÖ 6 Dimens√µes Implementadas:\n",
    "- **Completude**: `expect_column_values_to_not_be_null`\n",
    "- **Unicidade**: `expect_column_values_to_be_unique`\n",
    "- **Validade**: `expect_column_values_to_match_regex`, `expect_column_values_to_be_between`\n",
    "- **Consist√™ncia**: `expect_column_value_lengths_to_equal`\n",
    "- **Pontualidade**: `expect_column_values_to_be_between` (datas)\n",
    "- **Acur√°cia**: `expect_column_values_to_not_match_regex`\n",
    "\n",
    "#### ‚úÖ Pipeline DataOps Completo:\n",
    "- **Valida√ß√£o autom√°tica** com checkpoints\n",
    "- **Corre√ß√£o de dados** baseada em resultados\n",
    "- **Re-valida√ß√£o** para confirmar melhorias\n",
    "- **Relat√≥rios autom√°ticos** para stakeholders\n",
    "\n",
    "### üöÄ Pr√≥ximos Passos\n",
    "\n",
    "Para evoluir este laborat√≥rio:\n",
    "\n",
    "1. **Integra√ß√£o com Orquestradores**:\n",
    "   - Apache Airflow com Great Expectations\n",
    "   - Prefect para workflows complexos\n",
    "\n",
    "2. **Alertas Avan√ßados**:\n",
    "   - Slack/Teams para notifica√ß√µes\n",
    "   - Email autom√°tico para Data Stewards\n",
    "\n",
    "3. **M√©tricas Avan√ßadas**:\n",
    "   - Profiling autom√°tico de dados\n",
    "   - Detec√ß√£o de drift de dados\n",
    "\n",
    "### üí° Li√ß√µes Principais\n",
    "\n",
    "> **\"Great Expectations transforma valida√ß√µes ad-hoc em um sistema profissional de qualidade\"**\n",
    "\n",
    "- **Expectativas s√£o c√≥digo**: Version√°veis e test√°veis\n",
    "- **Automa√ß√£o √© fundamental**: Checkpoints eliminam trabalho manual\n",
    "- **Relat√≥rios s√£o essenciais**: Data Docs facilitam comunica√ß√£o\n",
    "- **Integra√ß√£o √© chave**: Great Expectations funciona com qualquer pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Limpeza do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalizar Spark Session\n",
    "spark.stop()\n",
    "print(\"‚úÖ Spark Session finalizada\")\n",
    "print(\"üéì Laborat√≥rio Great Expectations conclu√≠do com sucesso!\")\n",
    "print(\"\\nüìö Continue explorando Great Expectations para DataOps profissional!\")\n",
    "print(\"\\nüîó Recursos adicionais:\")\n",
    "print(\"   - Documenta√ß√£o: https://docs.greatexpectations.io/\")\n",
    "print(\"   - Galeria de Expectativas: https://greatexpectations.io/expectations/\")\n",
    "print(\"   - Comunidade: https://greatexpectations.io/community/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}