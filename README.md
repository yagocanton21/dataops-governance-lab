# ğŸš€ DataOps: GovernanÃ§a e Qualidade de Dados

## ğŸ“‹ Sobre o RepositÃ³rio

Este repositÃ³rio contÃ©m o material completo do curso **DataOps: GovernanÃ§a e Qualidade de Dados**, incluindo conceitos teÃ³ricos, laboratÃ³rios prÃ¡ticos com **PySpark** e **Great Expectations**, e um desafio final abrangente.

### ğŸ¯ Objetivos do Curso
- Dominar os **conceitos fundamentais** de DataOps: GovernanÃ§a de Dados
- Implementar **testes de qualidade** automatizados com Great Expectations
- Aplicar as **6 dimensÃµes da qualidade** de dados na prÃ¡tica
- Criar **pipelines DataOps** profissionais e escalÃ¡veis
- Desenvolver **soluÃ§Ãµes completas** de monitoramento e auditoria

## ğŸ“ Estrutura do RepositÃ³rio

```
aulaGovernanÃ§a/
â”œâ”€â”€ ğŸ“š Conceitos.md                             # Fundamentos teÃ³ricos
â”œâ”€â”€ ğŸ¯ Desafio_Final_DataOps.md                 # Desafio prÃ¡tico completo
â”œâ”€â”€ ğŸ“Š datasets/                                # Dados para o desafio
â”‚   â”œâ”€â”€ clientes.csv                            # Base de clientes (16 registros)
â”‚   â”œâ”€â”€ produtos.csv                            # CatÃ¡logo de produtos (20 registros)
â”‚   â”œâ”€â”€ vendas.csv                              # TransaÃ§Ãµes de vendas (25 registros)
â”‚   â”œâ”€â”€ logistica.csv                           # Dados de entrega (22 registros)
â”‚   â””â”€â”€ README.md                               # DocumentaÃ§Ã£o dos datasets
â”œâ”€â”€ ğŸ““ notebooks/                               # LaboratÃ³rios prÃ¡ticos
â”‚   â”œâ”€â”€ Lab_DataOps_Governanca_Qualidade.ipynb  # Lab com Great Expectations
â”‚   â””â”€â”€ exporaDataSets.ipynb                    # ExploraÃ§Ã£o dos datasets
â”œâ”€â”€ ğŸ³ Dockerfile                               # ConfiguraÃ§Ã£o do ambiente
â”œâ”€â”€ ğŸ³ docker-compose.yml                       # OrquestraÃ§Ã£o dos serviÃ§os
â””â”€â”€ ğŸ“– README.md                                # Este arquivo
```

## ğŸ› ï¸ Tecnologias Utilizadas

- **Great Expectations** - Framework profissional de validaÃ§Ã£o de dados
- **Pandas** - AnÃ¡lise e manipulaÃ§Ã£o de dados em Python
- **Jupyter Notebook** - Ambiente interativo de desenvolvimento
- **Docker** - ContainerizaÃ§Ã£o e isolamento do ambiente
- **CSV Files** - Datasets de exemplo para laboratÃ³rios

## ğŸ—ï¸ Arquitetura do Ambiente

### VisÃ£o Geral da Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Jupyter Lab   â”‚    â”‚   Apache Spark   â”‚    â”‚ Great Expect.   â”‚
â”‚   (Port 8888)   â”‚â—„â”€â”€â–ºâ”‚   + Iceberg      â”‚â—„â”€â”€â–ºâ”‚  Data Context   â”‚
â”‚                 â”‚    â”‚   (Port 4040)    â”‚    â”‚   Data Docs     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Docker Network    â”‚
                    â”‚  (172.16.240.0/24)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Data Sources     â”‚
                    â”‚  CSV Files + Spark  â”‚
                    â”‚   Iceberg Tables    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Arquitetura Docker Compose

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Host Machine                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Docker Compose Environment                   â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚           pyspark_aula_container                    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                                                     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚   Jupyter Lab   â”‚  â”‚ Great Expectationsâ”‚         â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚   (Port 8888)   â”‚  â”‚  Data Context   â”‚           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚                 â”‚  â”‚   Data Docs     â”‚           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                                                     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚     Pandas      â”‚  â”‚   CSV Datasets  â”‚           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚  Data Analysis  â”‚  â”‚ /notebooks/data â”‚           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚                 â”‚  â”‚                 â”‚           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  Network: plataform-network (172.16.240.0/24)             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  Volume Mappings:                                               â”‚
â”‚  ./notebooks  â†”  /home/tavares/work                             â”‚
â”‚  ./data       â†”  /home/tavares/data                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes da Arquitetura

#### ğŸ³ **Container Layer**
- **Base Image**: `jupyter/pyspark-notebook`
- **Custom User**: `tavares` (UID: 1001)
- **Working Directory**: `/home/tavares/work`
- **Volumes Mapeados**:
  - `./notebooks` â†’ `/home/tavares/work`
  - `./data` â†’ `/home/tavares/data`

#### ğŸ“Š **Data Processing Stack**
- **Pandas**: AnÃ¡lise de dados em Python
- **Great Expectations**: Framework de validaÃ§Ã£o de qualidade
- **Jupyter**: Ambiente interativo de desenvolvimento
- **CSV Files**: Datasets de exemplo para laboratÃ³rios

#### ğŸ¯ **Great Expectations Setup**
- **Data Context**: Configurado automaticamente
- **Datasources**: Pandas e Spark
- **Expectation Suites**: Para cada dataset
- **Checkpoints**: AutomaÃ§Ã£o de validaÃ§Ãµes
- **Data Docs**: RelatÃ³rios HTML profissionais

#### ğŸ“Š **Data Architecture**
```
Data Flow:
ğŸ“„ Raw CSV â†’ ğŸ Pandas â†’ ğŸ¯ Great Expectations â†’ ğŸ“ˆ Data Docs
                    â†“
                ğŸ“Š Quality Reports
```

### Portas e ServiÃ§os

| ServiÃ§o | Porta | DescriÃ§Ã£o |
|---------|-------|----------|
| **Jupyter Notebook** | 8888 | Interface principal de desenvolvimento |
| **Data Docs** | File System | RelatÃ³rios Great Expectations |
| **CSV Datasets** | File System | Dados de exemplo para laboratÃ³rios |

### Fluxo de Dados

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”€â”€â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”€â”€â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”€â”€â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw CSV   â”‚    â”‚   Pandas    â”‚    â”‚Great Expect.â”‚    â”‚ Data Docs   â”‚
â”‚   Datasets  â”‚    â”‚  DataFrame  â”‚    â”‚ Validation  â”‚    â”‚  Reports    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Cleaned    â”‚
                   â”‚   Dataset   â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### PersistÃªncia de Dados

```
Volume Mapping:
ğŸ“ Host                    ğŸ“¦ Container
./notebooks/          â†’   /home/tavares/work/
./data/               â†’   /home/tavares/data/
./datasets/           â†’   AcessÃ­vel via notebooks
```

## ğŸš€ ConfiguraÃ§Ã£o do Ambiente

### OpÃ§Ã£o 1: GitHub Codespaces (Recomendado)

1. **Abra o repositÃ³rio no GitHub Codespaces:**
   ```bash
   # Clique em "Code" > "Codespaces" > "Create codespace on main"
   # Ou use o link direto: https://github.com/AleTavares/dataops-governance-lab/codespaces
   ```

2. **Execute o ambiente com Docker Compose:**
   ```bash
   # No terminal do Codespace
   docker-compose up -d
   ```

3. **Acesse o Jupyter Notebook:**
   - URL: http://localhost:8888
   - Token: `tavares1234`
   - Spark UI: http://localhost:4040

4. **Acesse o laboratÃ³rio:**
   - Abra `notebooks/Lab_DataOps_Governanca_Qualidade.ipynb`
   - Execute as cÃ©lulas sequencialmente

### OpÃ§Ã£o 2: Docker (Ambiente Local)

1. **Clone o repositÃ³rio:**
   ```bash
   git clone https://github.com/AleTavares/dataops-governance-lab.git
   cd aulaGovernanca
   ```

2. **Construa e execute o ambiente:**
   ```bash
   # Construir a imagem Docker
   docker-compose build
   
   # Iniciar os serviÃ§os
   docker-compose up -d
   ```

3. **Acesse o Jupyter Notebook:**
   - URL: http://localhost:8888
   - Token: `tavares1234`
   - Spark UI: http://localhost:4040

4. **Verifique os volumes:**
   ```bash
   # Os notebooks estÃ£o em ./notebooks/
   # Os dados estÃ£o em ./data/
   # Arquivos sÃ£o persistidos automaticamente
   ```

## ğŸ“š Como Usar Este RepositÃ³rio

### 1. ğŸ“– Estude os Conceitos
- (Leia primeiro os fundamentos teÃ³ricos)[Conceitos.md]

### 2. ğŸ§ª Execute os LaboratÃ³rios
- (Explore os datasets primeiro)[notebooks/exporaDataSets.ipynb]
- (Execute o laboratÃ³rio principal)[notebooks/Lab_DataOps_Governanca_Qualidade.ipynb]

### 3. ğŸ¯ Realize o Desafio
(Desafio)[Desafio_Final_DataOps.md]

## ğŸ“ Roteiro de Aprendizagem

### MÃ³dulo 1: Fundamentos
1. ğŸ“š Leia (Conceitos)[Conceitos.md] completamente
2. ğŸ¯ Entenda os 4 pilares da governanÃ§a
3. ğŸ“Š Memorize as 6 dimensÃµes da qualidade

### MÃ³dulo 2: PrÃ¡tica
1. ğŸš€ Configure o ambiente (Docker ou Codespaces)
2. ğŸ“Š (Execute a exploraÃ§Ã£o dos dados)[exporaDataSets.ipynb]
3. ğŸ§ª Execute o laboratÃ³rio principal passo a passo
4. ğŸ” Experimente com Great Expectations
5. ğŸ“ˆ Analise os Data Docs gerados

### MÃ³dulo 3: Desafio
1. ğŸ“‹ (Leia)[Desafio_Final_DataOps.md] 
2. ğŸ” Analise os datasets fornecidos
3. ğŸ—ï¸ Implemente a soluÃ§Ã£o completa
4. ğŸ“Š Crie relatÃ³rios profissionais

## ğŸ”§ SoluÃ§Ã£o de Problemas

### Problema: Jupyter nÃ£o acessa
```bash
# Verifique se a porta estÃ¡ livre
netstat -tulpn | grep 8888

# Use porta alternativa
jupyter notebook --port=8889
```

### Problema: Great Expectations nÃ£o funciona
```bash
# 1. Reconstrua a imagem Docker com Great Expectations
docker-compose down
docker-compose build --no-cache
docker-compose up -d

# 2. Ou instale manualmente no container
docker exec -it pyspark_aula_container pip install great-expectations==0.18.8 sqlalchemy==1.4.46

# 3. Verifique a instalaÃ§Ã£o no notebook
import great_expectations as gx
print(gx.__version__)
```

### Problema: Jupyter nÃ£o acessa
```bash
# Verifique se a porta estÃ¡ livre
netstat -tulpn | grep 8888

# Use porta alternativa
jupyter notebook --port=8889
```

### Problema: Docker nÃ£o funciona
```bash
# Verifique se Docker estÃ¡ rodando
docker --version
docker-compose --version

# Reconstrua a imagem
docker-compose down
docker-compose build --no-cache
docker-compose up
```

## ğŸ“Š Notebooks DisponÃ­veis

### ğŸ” **exporaDataSets.ipynb** - ExploraÃ§Ã£o Inicial dos Dados
Notebook introdutÃ³rio que demonstra como:
- Carregar os 4 datasets do projeto TechCommerce
- Verificar estrutura e quantidade de registros
- Identificar valores nulos e problemas bÃ¡sicos
- Criar anÃ¡lises consolidadas dos dados

**Ideal para**: Primeiro contato com os dados e compreensÃ£o da estrutura.

### ğŸ§ª **Lab_DataOps_Governanca_Qualidade.ipynb** - LaboratÃ³rio Principal
LaboratÃ³rio completo com Great Expectations para:
- Implementar validaÃ§Ãµes de qualidade com pandas
- Aplicar as 6 dimensÃµes da qualidade
- Criar expectativas automatizadas
- Pipeline DataOps completo: validaÃ§Ã£o â†’ correÃ§Ã£o â†’ re-validaÃ§Ã£o

**Ideal para**: Aprendizado prÃ¡tico de DataOps e Great Expectations.

### ğŸ§ª **test_great_expectations.ipynb** - Teste do Ambiente
Notebook de diagnÃ³stico para:
- Verificar instalaÃ§Ã£o do Great Expectations
- Testar Data Context
- Validar configuraÃ§Ã£o do ambiente
- Executar testes bÃ¡sicos

**Ideal para**: DiagnÃ³stico de problemas e verificaÃ§Ã£o do ambiente.

## ğŸ“Š Datasets do Desafio

Os datasets simulam uma empresa de e-commerce (**TechCommerce**) com problemas reais de qualidade:

| Dataset | Registros | Problemas Principais |
|---------|-----------|---------------------|
| **clientes.csv** | 16 | Duplicatas, emails invÃ¡lidos, campos vazios |
| **produtos.csv** | 20 | PreÃ§os negativos, categorias vazias, duplicatas |
| **vendas.csv** | 25 | Integridade referencial, datas futuras, cÃ¡lculos incorretos |
| **logistica.csv** | 22 | Datas inconsistentes, campos vazios, duplicatas |

## ğŸ¤ ContribuiÃ§Ã£o

### Como Contribuir
1. Fork o repositÃ³rio
2. Crie uma branch para sua feature
3. FaÃ§a commit das mudanÃ§as
4. Abra um Pull Request

### Reportar Problemas
- Use as **Issues** do GitHub
- Inclua logs de erro completos
- Descreva o ambiente utilizado

### Recursos Adicionais
- ğŸ“š [DocumentaÃ§Ã£o Great Expectations](https://docs.greatexpectations.io/)
- ğŸ”¥ [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
- ğŸ³ [Docker Documentation](https://docs.docker.com/)

## ğŸ“„ LicenÃ§a
Este projeto estÃ¡ licenciado sob a **MIT License** - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ™ Agradecimentos

- **Apache Spark** pela plataforma de processamento distribuÃ­do
- **Great Expectations** pelo framework de qualidade de dados
- **Jupyter Project** pelo ambiente interativo
- **Docker** pela containerizaÃ§Ã£o
