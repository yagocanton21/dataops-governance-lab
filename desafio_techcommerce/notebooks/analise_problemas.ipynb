{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç An√°lise de Problemas de Qualidade - TechCommerce\n",
    "\n",
    "Este notebook identifica e classifica todos os problemas de qualidade nos datasets da TechCommerce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime, date\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√£o para exibir todas as colunas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Carregamento dos Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento dos datasets\n",
    "clientes_df = pd.read_csv('../data/raw/clientes.csv')\n",
    "produtos_df = pd.read_csv('../data/raw/produtos.csv')\n",
    "vendas_df = pd.read_csv('../data/raw/vendas.csv')\n",
    "logistica_df = pd.read_csv('../data/raw/logistica.csv')\n",
    "\n",
    "print(\"üìä Datasets carregados:\")\n",
    "print(f\"Clientes: {len(clientes_df)} registros\")\n",
    "print(f\"Produtos: {len(produtos_df)} registros\")\n",
    "print(f\"Vendas: {len(vendas_df)} registros\")\n",
    "print(f\"Log√≠stica: {len(logistica_df)} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç An√°lise de Problemas por Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_problemas_clientes(df):\n",
    "    problemas = []\n",
    "    total_registros = len(df)\n",
    "    \n",
    "    # 1. COMPLETUDE\n",
    "    nulos_nome = df['nome'].isnull().sum()\n",
    "    nulos_email = df['email'].isnull().sum()\n",
    "    vazios_nome = (df['nome'] == '').sum()\n",
    "    \n",
    "    if nulos_nome > 0 or vazios_nome > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'clientes',\n",
    "            'dimensao': 'Completude',\n",
    "            'problema': 'Nomes nulos ou vazios',\n",
    "            'registros_afetados': nulos_nome + vazios_nome,\n",
    "            'percentual': ((nulos_nome + vazios_nome) / total_registros) * 100,\n",
    "            'criticidade': 'Cr√≠tico'\n",
    "        })\n",
    "    \n",
    "    if nulos_email > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'clientes',\n",
    "            'dimensao': 'Completude',\n",
    "            'problema': 'Emails nulos',\n",
    "            'registros_afetados': nulos_email,\n",
    "            'percentual': (nulos_email / total_registros) * 100,\n",
    "            'criticidade': 'Alto'\n",
    "        })\n",
    "    \n",
    "    # 2. UNICIDADE\n",
    "    duplicatas_id = df['id_cliente'].duplicated().sum()\n",
    "    if duplicatas_id > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'clientes',\n",
    "            'dimensao': 'Unicidade',\n",
    "            'problema': 'IDs duplicados',\n",
    "            'registros_afetados': duplicatas_id,\n",
    "            'percentual': (duplicatas_id / total_registros) * 100,\n",
    "            'criticidade': 'Cr√≠tico'\n",
    "        })\n",
    "    \n",
    "    # 3. VALIDADE\n",
    "    emails_invalidos = 0\n",
    "    telefones_invalidos = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if pd.notna(row['email']) and not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', str(row['email'])):\n",
    "            emails_invalidos += 1\n",
    "        \n",
    "        if pd.notna(row['telefone']) and not re.match(r'^[1-9][1-9][0-9]{9}$', str(row['telefone'])):\n",
    "            telefones_invalidos += 1\n",
    "    \n",
    "    if emails_invalidos > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'clientes',\n",
    "            'dimensao': 'Validade',\n",
    "            'problema': 'Emails com formato inv√°lido',\n",
    "            'registros_afetados': emails_invalidos,\n",
    "            'percentual': (emails_invalidos / total_registros) * 100,\n",
    "            'criticidade': 'Alto'\n",
    "        })\n",
    "    \n",
    "    if telefones_invalidos > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'clientes',\n",
    "            'dimensao': 'Validade',\n",
    "            'problema': 'Telefones com formato inv√°lido',\n",
    "            'registros_afetados': telefones_invalidos,\n",
    "            'percentual': (telefones_invalidos / total_registros) * 100,\n",
    "            'criticidade': 'M√©dio'\n",
    "        })\n",
    "    \n",
    "    return problemas\n",
    "\n",
    "# An√°lise dos clientes\n",
    "problemas_clientes = analisar_problemas_clientes(clientes_df)\n",
    "print(\"üîç Problemas encontrados em CLIENTES:\")\n",
    "for p in problemas_clientes:\n",
    "    print(f\"  ‚Ä¢ {p['problema']}: {p['registros_afetados']} registros ({p['percentual']:.1f}%) - {p['criticidade']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_problemas_produtos(df):\n",
    "    problemas = []\n",
    "    total_registros = len(df)\n",
    "    \n",
    "    # 1. COMPLETUDE\n",
    "    nulos_categoria = df['categoria'].isnull().sum()\n",
    "    vazios_categoria = (df['categoria'] == '').sum()\n",
    "    \n",
    "    if nulos_categoria > 0 or vazios_categoria > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'produtos',\n",
    "            'dimensao': 'Completude',\n",
    "            'problema': 'Categorias nulas ou vazias',\n",
    "            'registros_afetados': nulos_categoria + vazios_categoria,\n",
    "            'percentual': ((nulos_categoria + vazios_categoria) / total_registros) * 100,\n",
    "            'criticidade': 'Alto'\n",
    "        })\n",
    "    \n",
    "    # 2. UNICIDADE\n",
    "    duplicatas_id = df['id_produto'].duplicated().sum()\n",
    "    if duplicatas_id > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'produtos',\n",
    "            'dimensao': 'Unicidade',\n",
    "            'problema': 'IDs duplicados',\n",
    "            'registros_afetados': duplicatas_id,\n",
    "            'percentual': (duplicatas_id / total_registros) * 100,\n",
    "            'criticidade': 'Cr√≠tico'\n",
    "        })\n",
    "    \n",
    "    # Duplicatas de produto (mesmo nome + categoria)\n",
    "    duplicatas_produto = df.duplicated(subset=['nome_produto', 'categoria']).sum()\n",
    "    if duplicatas_produto > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'produtos',\n",
    "            'dimensao': 'Unicidade',\n",
    "            'problema': 'Produtos duplicados (nome + categoria)',\n",
    "            'registros_afetados': duplicatas_produto,\n",
    "            'percentual': (duplicatas_produto / total_registros) * 100,\n",
    "            'criticidade': 'Alto'\n",
    "        })\n",
    "    \n",
    "    # 3. VALIDADE\n",
    "    precos_negativos = (df['preco'] < 0).sum()\n",
    "    estoque_negativo = (df['estoque'] < 0).sum()\n",
    "    \n",
    "    if precos_negativos > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'produtos',\n",
    "            'dimensao': 'Validade',\n",
    "            'problema': 'Pre√ßos negativos',\n",
    "            'registros_afetados': precos_negativos,\n",
    "            'percentual': (precos_negativos / total_registros) * 100,\n",
    "            'criticidade': 'Cr√≠tico'\n",
    "        })\n",
    "    \n",
    "    if estoque_negativo > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'produtos',\n",
    "            'dimensao': 'Validade',\n",
    "            'problema': 'Estoque negativo',\n",
    "            'registros_afetados': estoque_negativo,\n",
    "            'percentual': (estoque_negativo / total_registros) * 100,\n",
    "            'criticidade': 'Alto'\n",
    "        })\n",
    "    \n",
    "    return problemas\n",
    "\n",
    "# An√°lise dos produtos\n",
    "problemas_produtos = analisar_problemas_produtos(produtos_df)\n",
    "print(\"\\nüîç Problemas encontrados em PRODUTOS:\")\n",
    "for p in problemas_produtos:\n",
    "    print(f\"  ‚Ä¢ {p['problema']}: {p['registros_afetados']} registros ({p['percentual']:.1f}%) - {p['criticidade']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_problemas_vendas(df, clientes_df, produtos_df):\n",
    "    problemas = []\n",
    "    total_registros = len(df)\n",
    "    \n",
    "    # 1. VALIDADE\n",
    "    quantidades_negativas = (df['quantidade'] <= 0).sum()\n",
    "    valores_negativos = (df['valor_total'] < 0).sum()\n",
    "    \n",
    "    if quantidades_negativas > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'vendas',\n",
    "            'dimensao': 'Validade',\n",
    "            'problema': 'Quantidades negativas ou zero',\n",
    "            'registros_afetados': quantidades_negativas,\n",
    "            'percentual': (quantidades_negativas / total_registros) * 100,\n",
    "            'criticidade': 'Cr√≠tico'\n",
    "        })\n",
    "    \n",
    "    if valores_negativos > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'vendas',\n",
    "            'dimensao': 'Validade',\n",
    "            'problema': 'Valores totais negativos',\n",
    "            'registros_afetados': valores_negativos,\n",
    "            'percentual': (valores_negativos / total_registros) * 100,\n",
    "            'criticidade': 'Cr√≠tico'\n",
    "        })\n",
    "    \n",
    "    # 2. INTEGRIDADE REFERENCIAL\n",
    "    clientes_validos = set(clientes_df['id_cliente'].unique())\n",
    "    produtos_validos = set(produtos_df['id_produto'].unique())\n",
    "    \n",
    "    clientes_orfaos = df[~df['id_cliente'].isin(clientes_validos)].shape[0]\n",
    "    produtos_orfaos = df[~df['id_produto'].isin(produtos_validos)].shape[0]\n",
    "    \n",
    "    if clientes_orfaos > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'vendas',\n",
    "            'dimensao': 'Integridade',\n",
    "            'problema': 'Refer√™ncias √≥rf√£s para clientes',\n",
    "            'registros_afetados': clientes_orfaos,\n",
    "            'percentual': (clientes_orfaos / total_registros) * 100,\n",
    "            'criticidade': 'Cr√≠tico'\n",
    "        })\n",
    "    \n",
    "    if produtos_orfaos > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'vendas',\n",
    "            'dimensao': 'Integridade',\n",
    "            'problema': 'Refer√™ncias √≥rf√£s para produtos',\n",
    "            'registros_afetados': produtos_orfaos,\n",
    "            'percentual': (produtos_orfaos / total_registros) * 100,\n",
    "            'criticidade': 'Cr√≠tico'\n",
    "        })\n",
    "    \n",
    "    # 3. CONSIST√äNCIA\n",
    "    inconsistencias_calculo = 0\n",
    "    datas_futuras = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Verificar c√°lculo valor_total\n",
    "        valor_esperado = row['quantidade'] * row['valor_unitario']\n",
    "        if abs(row['valor_total'] - valor_esperado) > 0.01:  # toler√¢ncia de 1 centavo\n",
    "            inconsistencias_calculo += 1\n",
    "        \n",
    "        # Verificar datas futuras\n",
    "        try:\n",
    "            data_venda = pd.to_datetime(row['data_venda']).date()\n",
    "            if data_venda > date.today():\n",
    "                datas_futuras += 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if inconsistencias_calculo > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'vendas',\n",
    "            'dimensao': 'Consist√™ncia',\n",
    "            'problema': 'Inconsist√™ncia no c√°lculo valor_total',\n",
    "            'registros_afetados': inconsistencias_calculo,\n",
    "            'percentual': (inconsistencias_calculo / total_registros) * 100,\n",
    "            'criticidade': 'Alto'\n",
    "        })\n",
    "    \n",
    "    if datas_futuras > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'vendas',\n",
    "            'dimensao': 'Atualidade',\n",
    "            'problema': 'Datas de venda futuras',\n",
    "            'registros_afetados': datas_futuras,\n",
    "            'percentual': (datas_futuras / total_registros) * 100,\n",
    "            'criticidade': 'Cr√≠tico'\n",
    "        })\n",
    "    \n",
    "    return problemas\n",
    "\n",
    "# An√°lise das vendas\n",
    "problemas_vendas = analisar_problemas_vendas(vendas_df, clientes_df, produtos_df)\n",
    "print(\"\\nüîç Problemas encontrados em VENDAS:\")\n",
    "for p in problemas_vendas:\n",
    "    print(f\"  ‚Ä¢ {p['problema']}: {p['registros_afetados']} registros ({p['percentual']:.1f}%) - {p['criticidade']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisar_problemas_logistica(df, vendas_df):\n",
    "    problemas = []\n",
    "    total_registros = len(df)\n",
    "    \n",
    "    # 1. COMPLETUDE\n",
    "    nulos_transportadora = df['transportadora'].isnull().sum()\n",
    "    vazios_transportadora = (df['transportadora'] == '').sum()\n",
    "    nulos_data_envio = df['data_envio'].isnull().sum()\n",
    "    \n",
    "    if nulos_transportadora > 0 or vazios_transportadora > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'logistica',\n",
    "            'dimensao': 'Completude',\n",
    "            'problema': 'Transportadora nula ou vazia',\n",
    "            'registros_afetados': nulos_transportadora + vazios_transportadora,\n",
    "            'percentual': ((nulos_transportadora + vazios_transportadora) / total_registros) * 100,\n",
    "            'criticidade': 'Alto'\n",
    "        })\n",
    "    \n",
    "    if nulos_data_envio > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'logistica',\n",
    "            'dimensao': 'Completude',\n",
    "            'problema': 'Data de envio nula',\n",
    "            'registros_afetados': nulos_data_envio,\n",
    "            'percentual': (nulos_data_envio / total_registros) * 100,\n",
    "            'criticidade': 'Alto'\n",
    "        })\n",
    "    \n",
    "    # 2. INTEGRIDADE REFERENCIAL\n",
    "    vendas_validas = set(vendas_df['id_venda'].unique())\n",
    "    vendas_orfaos = df[~df['id_venda'].isin(vendas_validas)].shape[0]\n",
    "    \n",
    "    if vendas_orfaos > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'logistica',\n",
    "            'dimensao': 'Integridade',\n",
    "            'problema': 'Refer√™ncias √≥rf√£s para vendas',\n",
    "            'registros_afetados': vendas_orfaos,\n",
    "            'percentual': (vendas_orfaos / total_registros) * 100,\n",
    "            'criticidade': 'Cr√≠tico'\n",
    "        })\n",
    "    \n",
    "    # 3. CONSIST√äNCIA\n",
    "    inconsistencias_datas = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            if pd.notna(row['data_envio']) and pd.notna(row['data_entrega_real']):\n",
    "                data_envio = pd.to_datetime(row['data_envio'])\n",
    "                data_entrega = pd.to_datetime(row['data_entrega_real'])\n",
    "                if data_entrega < data_envio:\n",
    "                    inconsistencias_datas += 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if inconsistencias_datas > 0:\n",
    "        problemas.append({\n",
    "            'dataset': 'logistica',\n",
    "            'dimensao': 'Consist√™ncia',\n",
    "            'problema': 'Data entrega anterior ao envio',\n",
    "            'registros_afetados': inconsistencias_datas,\n",
    "            'percentual': (inconsistencias_datas / total_registros) * 100,\n",
    "            'criticidade': 'Alto'\n",
    "        })\n",
    "    \n",
    "    return problemas\n",
    "\n",
    "# An√°lise da log√≠stica\n",
    "problemas_logistica = analisar_problemas_logistica(logistica_df, vendas_df)\n",
    "print(\"\\nüîç Problemas encontrados em LOG√çSTICA:\")\n",
    "for p in problemas_logistica:\n",
    "    print(f\"  ‚Ä¢ {p['problema']}: {p['registros_afetados']} registros ({p['percentual']:.1f}%) - {p['criticidade']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Consolida√ß√£o e Prioriza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidar todos os problemas\n",
    "todos_problemas = problemas_clientes + problemas_produtos + problemas_vendas + problemas_logistica\n",
    "\n",
    "# Criar DataFrame para an√°lise\n",
    "df_problemas = pd.DataFrame(todos_problemas)\n",
    "\n",
    "# Ordenar por criticidade e percentual\n",
    "ordem_criticidade = {'Cr√≠tico': 4, 'Alto': 3, 'M√©dio': 2, 'Baixo': 1}\n",
    "df_problemas['ordem_criticidade'] = df_problemas['criticidade'].map(ordem_criticidade)\n",
    "df_problemas = df_problemas.sort_values(['ordem_criticidade', 'percentual'], ascending=[False, False])\n",
    "\n",
    "print(\"üìä RESUMO EXECUTIVO - Problemas de Qualidade TechCommerce\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Estat√≠sticas gerais\n",
    "total_problemas = len(df_problemas)\n",
    "problemas_criticos = len(df_problemas[df_problemas['criticidade'] == 'Cr√≠tico'])\n",
    "problemas_altos = len(df_problemas[df_problemas['criticidade'] == 'Alto'])\n",
    "\n",
    "print(f\"\\nüö® TOTAL DE PROBLEMAS IDENTIFICADOS: {total_problemas}\")\n",
    "print(f\"   ‚Ä¢ Cr√≠ticos: {problemas_criticos}\")\n",
    "print(f\"   ‚Ä¢ Altos: {problemas_altos}\")\n",
    "print(f\"   ‚Ä¢ M√©dios: {len(df_problemas[df_problemas['criticidade'] == 'M√©dio'])}\")\n",
    "\n",
    "print(\"\\nüéØ TOP 10 PROBLEMAS PRIORIT√ÅRIOS:\")\n",
    "for idx, row in df_problemas.head(10).iterrows():\n",
    "    print(f\"   {idx+1:2d}. [{row['dataset'].upper()}] {row['problema']}\")\n",
    "    print(f\"       Dimens√£o: {row['dimensao']} | Impacto: {row['percentual']:.1f}% | Criticidade: {row['criticidade']}\")\n",
    "    print()\n",
    "\n",
    "# An√°lise por dimens√£o\n",
    "print(\"\\nüìä PROBLEMAS POR DIMENS√ÉO DA QUALIDADE:\")\n",
    "dimensoes = df_problemas.groupby('dimensao').agg({\n",
    "    'problema': 'count',\n",
    "    'registros_afetados': 'sum',\n",
    "    'percentual': 'mean'\n",
    "}).round(1)\n",
    "dimensoes.columns = ['Qtd_Problemas', 'Total_Registros_Afetados', 'Percentual_Medio']\n",
    "print(dimensoes.sort_values('Qtd_Problemas', ascending=False))\n",
    "\n",
    "# An√°lise por dataset\n",
    "print(\"\\nüìä PROBLEMAS POR DATASET:\")\n",
    "datasets = df_problemas.groupby('dataset').agg({\n",
    "    'problema': 'count',\n",
    "    'registros_afetados': 'sum',\n",
    "    'percentual': 'mean'\n",
    "}).round(1)\n",
    "datasets.columns = ['Qtd_Problemas', 'Total_Registros_Afetados', 'Percentual_Medio']\n",
    "print(datasets.sort_values('Qtd_Problemas', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Exportar Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar an√°lise completa\n",
    "df_problemas.drop('ordem_criticidade', axis=1).to_csv('../data/quality/analise_problemas_completa.csv', index=False)\n",
    "\n",
    "# Criar relat√≥rio executivo\n",
    "relatorio = f\"\"\"\n",
    "# üìä Relat√≥rio Executivo - An√°lise de Qualidade de Dados TechCommerce\n",
    "\n",
    "## Resumo Executivo\n",
    "- **Total de problemas identificados**: {total_problemas}\n",
    "- **Problemas cr√≠ticos**: {problemas_criticos} (requerem a√ß√£o imediata)\n",
    "- **Problemas de alta prioridade**: {problemas_altos}\n",
    "\n",
    "## Principais Achados\n",
    "1. **Integridade Referencial**: Vendas com refer√™ncias √≥rf√£s para clientes inexistentes\n",
    "2. **Validade de Dados**: Pre√ßos negativos e quantidades inv√°lidas\n",
    "3. **Completude**: Campos obrigat√≥rios vazios em m√∫ltiplos datasets\n",
    "4. **Unicidade**: Duplicatas em chaves prim√°rias\n",
    "\n",
    "## Recomenda√ß√µes Imediatas\n",
    "1. Implementar valida√ß√µes de integridade referencial\n",
    "2. Corrigir valores negativos em pre√ßos e quantidades\n",
    "3. Estabelecer processo de deduplica√ß√£o\n",
    "4. Implementar valida√ß√£o de formatos (emails, telefones)\n",
    "\n",
    "## Impacto no Neg√≥cio\n",
    "- **Receita**: Vendas com valores negativos impactam faturamento\n",
    "- **Opera√ß√µes**: Refer√™ncias √≥rf√£s impedem processamento correto\n",
    "- **Compliance**: Dados incompletos violam pol√≠ticas de governan√ßa\n",
    "- **Decis√µes**: Dados inconsistentes comprometem an√°lises\n",
    "\"\"\"\n",
    "\n",
    "with open('../data/quality/relatorio_executivo_problemas.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(relatorio)\n",
    "\n",
    "print(\"‚úÖ An√°lise completa salva em:\")\n",
    "print(\"   ‚Ä¢ ../data/quality/analise_problemas_completa.csv\")\n",
    "print(\"   ‚Ä¢ ../data/quality/relatorio_executivo_problemas.md\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}